# Berkeley CS182/282A: Deep Neural Networks

This repository contains my course work for **CS182/282A â€“ Deep Neural Networks** at **UC Berkeley**.

UC Berkeley's CS182/282A offers a rigorous deep dive into the mathematical and practical foundations of deep learning. The curriculum spans from advanced optimization and scaling theory (muP, MuON, and implicit regularization) to architectures including CNNs, GNNs, Transformers, and State-Space Models (SSMs). It culminates in modern LLM frontiers, covering Parameter-Efficient Fine-Tuning (LoRA), In-context Learning, and Generative paradigms (Diffusion), providing a comprehensive toolkit for understanding and scaling frontier AI models.

Course website: https://berkeley-cs182.github.io/

---

## ğŸ“š Contents

### ğŸ“ Notes
- Lecture notes and personal summaries
- Mathematical derivations and conceptual explanations
- Additional insights and references beyond the lectures

### ğŸ§ª Assignments
- Programming assignments and experiments
- Implementations of core deep learning algorithms
- Analysis of results and observations

---

## ğŸ§  Topics Covered

The curriculum focuses on the theoretical and practical aspects of deep learning. Key highlights include:
- **Optimization Theory**: Beyond basic SGDâ€”implicit regularization, muP, and MuON.
- **Architectures**: From ResNets and GNNs to the latest in SSMs and Transformers.
- **Modern LLM Tech**: PEFT (LoRA), In-context learning, and Meta-Learning.
- **Generative AI**: Detailed exploration of Diffusion and Post-training.

---

## âš ï¸ Academic Integrity

This repository is intended **for personal learning and reference only**.
Please do not copy or submit any part of this work as your own coursework.

---

## ğŸ“– References

- CS182/282A: Deep Neural Networks (UC Berkeley)
- Course lecture slides and official materials
- Relevant research papers and textbooks
